{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import yelp_api_key\n",
    "from config import darksky_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sales Data\n",
    "file = 'bar_x_sales_export.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Dates\n",
    "start_date = '2017-01-01' # Start Date Inclusive\n",
    "end_date = '2019-06-01' # End Date Exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_business = 'Jupiter Disco'\n",
    "location = 'Brooklyn, NY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import / Clean / Prep File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bar_x_sales_export.csv\" has been imported + parsed. The file has 891 rows.\n"
     ]
    }
   ],
   "source": [
    "def import_parse(file):\n",
    "\n",
    "    data = pd.read_csv(file, index_col = 'date', parse_dates=True)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Rename Column to 'sales'\n",
    "    df = df.rename(columns={df.columns[0]: 'sales'})\n",
    "    \n",
    "    # Drop NaN\n",
    "    #df = df.query('sales > 0').copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    print(f'\"{file}\" has been imported + parsed. The file has {len(df)} rows.')\n",
    "    return df\n",
    "\n",
    "df = import_parse(file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, start_date, end_date):\n",
    "    \n",
    "    return df[(df.index > start_date) & (df.index < end_date)]\n",
    "    \n",
    "df = filter_df(df, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>2017</th>\n",
       "      <td>516.3860</td>\n",
       "      <td>647.48250</td>\n",
       "      <td>1183.9425</td>\n",
       "      <td>491.2050</td>\n",
       "      <td>543.816000</td>\n",
       "      <td>555.365000</td>\n",
       "      <td>1212.406000</td>\n",
       "      <td>533.020000</td>\n",
       "      <td>418.412500</td>\n",
       "      <td>529.060000</td>\n",
       "      <td>735.852500</td>\n",
       "      <td>496.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>398.2020</td>\n",
       "      <td>407.79750</td>\n",
       "      <td>1252.3050</td>\n",
       "      <td>313.9940</td>\n",
       "      <td>475.595000</td>\n",
       "      <td>1573.685511</td>\n",
       "      <td>376.968794</td>\n",
       "      <td>690.178243</td>\n",
       "      <td>455.241160</td>\n",
       "      <td>902.620590</td>\n",
       "      <td>1154.696929</td>\n",
       "      <td>1207.864237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>449.1125</td>\n",
       "      <td>381.10750</td>\n",
       "      <td>625.6675</td>\n",
       "      <td>390.3160</td>\n",
       "      <td>440.072500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>2017</th>\n",
       "      <td>878.5540</td>\n",
       "      <td>688.02000</td>\n",
       "      <td>819.7400</td>\n",
       "      <td>780.1650</td>\n",
       "      <td>727.966000</td>\n",
       "      <td>729.102500</td>\n",
       "      <td>691.960000</td>\n",
       "      <td>779.938000</td>\n",
       "      <td>496.820000</td>\n",
       "      <td>1074.068000</td>\n",
       "      <td>631.415000</td>\n",
       "      <td>585.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>808.3400</td>\n",
       "      <td>1208.02000</td>\n",
       "      <td>610.0475</td>\n",
       "      <td>775.2675</td>\n",
       "      <td>759.864000</td>\n",
       "      <td>1676.605227</td>\n",
       "      <td>1065.680822</td>\n",
       "      <td>800.896800</td>\n",
       "      <td>715.204696</td>\n",
       "      <td>737.921757</td>\n",
       "      <td>903.176949</td>\n",
       "      <td>605.239133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>613.3100</td>\n",
       "      <td>580.39750</td>\n",
       "      <td>686.0950</td>\n",
       "      <td>934.6300</td>\n",
       "      <td>815.617500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>2017</th>\n",
       "      <td>829.3400</td>\n",
       "      <td>1149.60250</td>\n",
       "      <td>1090.1660</td>\n",
       "      <td>858.7200</td>\n",
       "      <td>955.394000</td>\n",
       "      <td>830.735000</td>\n",
       "      <td>637.622500</td>\n",
       "      <td>665.670000</td>\n",
       "      <td>645.045000</td>\n",
       "      <td>876.327500</td>\n",
       "      <td>1548.482000</td>\n",
       "      <td>820.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>725.4540</td>\n",
       "      <td>1342.47750</td>\n",
       "      <td>717.5500</td>\n",
       "      <td>995.0500</td>\n",
       "      <td>776.454000</td>\n",
       "      <td>1161.861426</td>\n",
       "      <td>1137.068591</td>\n",
       "      <td>971.995906</td>\n",
       "      <td>1286.541929</td>\n",
       "      <td>1667.758492</td>\n",
       "      <td>1003.392882</td>\n",
       "      <td>857.146338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>735.0040</td>\n",
       "      <td>649.08750</td>\n",
       "      <td>1626.9850</td>\n",
       "      <td>1120.8225</td>\n",
       "      <td>716.862000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>2017</th>\n",
       "      <td>1355.0125</td>\n",
       "      <td>1357.96000</td>\n",
       "      <td>908.7360</td>\n",
       "      <td>1166.2575</td>\n",
       "      <td>1293.222500</td>\n",
       "      <td>1025.390000</td>\n",
       "      <td>1074.647500</td>\n",
       "      <td>1182.468000</td>\n",
       "      <td>1332.415000</td>\n",
       "      <td>762.650000</td>\n",
       "      <td>1256.718000</td>\n",
       "      <td>1510.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1183.1725</td>\n",
       "      <td>1066.41475</td>\n",
       "      <td>1345.5960</td>\n",
       "      <td>1346.2375</td>\n",
       "      <td>1545.610505</td>\n",
       "      <td>1236.101679</td>\n",
       "      <td>1115.645611</td>\n",
       "      <td>1361.021963</td>\n",
       "      <td>1242.712945</td>\n",
       "      <td>1014.373708</td>\n",
       "      <td>881.618083</td>\n",
       "      <td>1706.367905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1157.4340</td>\n",
       "      <td>1268.69000</td>\n",
       "      <td>1112.1200</td>\n",
       "      <td>1728.0250</td>\n",
       "      <td>1403.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>2017</th>\n",
       "      <td>2827.9725</td>\n",
       "      <td>3204.24750</td>\n",
       "      <td>3060.9860</td>\n",
       "      <td>2949.0750</td>\n",
       "      <td>3289.650000</td>\n",
       "      <td>2912.632000</td>\n",
       "      <td>2128.480000</td>\n",
       "      <td>3182.207500</td>\n",
       "      <td>3674.406000</td>\n",
       "      <td>3193.820000</td>\n",
       "      <td>3979.102500</td>\n",
       "      <td>2900.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3065.4600</td>\n",
       "      <td>4349.03750</td>\n",
       "      <td>4042.1680</td>\n",
       "      <td>4316.6850</td>\n",
       "      <td>3706.467500</td>\n",
       "      <td>4080.084032</td>\n",
       "      <td>3189.473347</td>\n",
       "      <td>3908.243814</td>\n",
       "      <td>4170.388811</td>\n",
       "      <td>3877.366825</td>\n",
       "      <td>3946.826055</td>\n",
       "      <td>3608.728645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>3487.0125</td>\n",
       "      <td>4170.30000</td>\n",
       "      <td>3691.6700</td>\n",
       "      <td>4244.4200</td>\n",
       "      <td>3902.230000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>2017</th>\n",
       "      <td>2920.9700</td>\n",
       "      <td>3991.26250</td>\n",
       "      <td>3673.6275</td>\n",
       "      <td>3290.3240</td>\n",
       "      <td>3079.322500</td>\n",
       "      <td>3354.785000</td>\n",
       "      <td>2944.338000</td>\n",
       "      <td>2830.012500</td>\n",
       "      <td>3136.190000</td>\n",
       "      <td>3370.617500</td>\n",
       "      <td>4209.540000</td>\n",
       "      <td>2735.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>4337.5900</td>\n",
       "      <td>4444.53750</td>\n",
       "      <td>4625.7580</td>\n",
       "      <td>4243.9700</td>\n",
       "      <td>3694.255000</td>\n",
       "      <td>4341.739711</td>\n",
       "      <td>3875.997336</td>\n",
       "      <td>4075.045577</td>\n",
       "      <td>3768.836186</td>\n",
       "      <td>4195.143800</td>\n",
       "      <td>4704.352842</td>\n",
       "      <td>3229.293940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>3573.1525</td>\n",
       "      <td>4498.55500</td>\n",
       "      <td>4450.1420</td>\n",
       "      <td>4623.2500</td>\n",
       "      <td>4610.585000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th>2017</th>\n",
       "      <td>1074.6900</td>\n",
       "      <td>1550.90000</td>\n",
       "      <td>643.9475</td>\n",
       "      <td>761.9100</td>\n",
       "      <td>1310.082500</td>\n",
       "      <td>675.692500</td>\n",
       "      <td>605.934000</td>\n",
       "      <td>533.185000</td>\n",
       "      <td>941.972500</td>\n",
       "      <td>529.680000</td>\n",
       "      <td>602.042500</td>\n",
       "      <td>940.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>678.0800</td>\n",
       "      <td>1070.21750</td>\n",
       "      <td>705.7325</td>\n",
       "      <td>744.2500</td>\n",
       "      <td>1853.280000</td>\n",
       "      <td>652.400316</td>\n",
       "      <td>892.488110</td>\n",
       "      <td>726.787170</td>\n",
       "      <td>1332.109718</td>\n",
       "      <td>418.156200</td>\n",
       "      <td>726.923393</td>\n",
       "      <td>862.469685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>743.0425</td>\n",
       "      <td>747.23250</td>\n",
       "      <td>799.1100</td>\n",
       "      <td>662.0525</td>\n",
       "      <td>1955.124000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sales                                                 \\\n",
       "month            1           2          3          4            5    \n",
       "day year                                                             \n",
       "0   2017   516.3860   647.48250  1183.9425   491.2050   543.816000   \n",
       "    2018   398.2020   407.79750  1252.3050   313.9940   475.595000   \n",
       "    2019   449.1125   381.10750   625.6675   390.3160   440.072500   \n",
       "1   2017   878.5540   688.02000   819.7400   780.1650   727.966000   \n",
       "    2018   808.3400  1208.02000   610.0475   775.2675   759.864000   \n",
       "    2019   613.3100   580.39750   686.0950   934.6300   815.617500   \n",
       "2   2017   829.3400  1149.60250  1090.1660   858.7200   955.394000   \n",
       "    2018   725.4540  1342.47750   717.5500   995.0500   776.454000   \n",
       "    2019   735.0040   649.08750  1626.9850  1120.8225   716.862000   \n",
       "3   2017  1355.0125  1357.96000   908.7360  1166.2575  1293.222500   \n",
       "    2018  1183.1725  1066.41475  1345.5960  1346.2375  1545.610505   \n",
       "    2019  1157.4340  1268.69000  1112.1200  1728.0250  1403.620000   \n",
       "4   2017  2827.9725  3204.24750  3060.9860  2949.0750  3289.650000   \n",
       "    2018  3065.4600  4349.03750  4042.1680  4316.6850  3706.467500   \n",
       "    2019  3487.0125  4170.30000  3691.6700  4244.4200  3902.230000   \n",
       "5   2017  2920.9700  3991.26250  3673.6275  3290.3240  3079.322500   \n",
       "    2018  4337.5900  4444.53750  4625.7580  4243.9700  3694.255000   \n",
       "    2019  3573.1525  4498.55500  4450.1420  4623.2500  4610.585000   \n",
       "6   2017  1074.6900  1550.90000   643.9475   761.9100  1310.082500   \n",
       "    2018   678.0800  1070.21750   705.7325   744.2500  1853.280000   \n",
       "    2019   743.0425   747.23250   799.1100   662.0525  1955.124000   \n",
       "\n",
       "                                                                           \\\n",
       "month              6            7            8            9            10   \n",
       "day year                                                                    \n",
       "0   2017   555.365000  1212.406000   533.020000   418.412500   529.060000   \n",
       "    2018  1573.685511   376.968794   690.178243   455.241160   902.620590   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "1   2017   729.102500   691.960000   779.938000   496.820000  1074.068000   \n",
       "    2018  1676.605227  1065.680822   800.896800   715.204696   737.921757   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "2   2017   830.735000   637.622500   665.670000   645.045000   876.327500   \n",
       "    2018  1161.861426  1137.068591   971.995906  1286.541929  1667.758492   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "3   2017  1025.390000  1074.647500  1182.468000  1332.415000   762.650000   \n",
       "    2018  1236.101679  1115.645611  1361.021963  1242.712945  1014.373708   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "4   2017  2912.632000  2128.480000  3182.207500  3674.406000  3193.820000   \n",
       "    2018  4080.084032  3189.473347  3908.243814  4170.388811  3877.366825   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "5   2017  3354.785000  2944.338000  2830.012500  3136.190000  3370.617500   \n",
       "    2018  4341.739711  3875.997336  4075.045577  3768.836186  4195.143800   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "6   2017   675.692500   605.934000   533.185000   941.972500   529.680000   \n",
       "    2018   652.400316   892.488110   726.787170  1332.109718   418.156200   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "                                    \n",
       "month              11           12  \n",
       "day year                            \n",
       "0   2017   735.852500   496.392500  \n",
       "    2018  1154.696929  1207.864237  \n",
       "    2019          NaN          NaN  \n",
       "1   2017   631.415000   585.697500  \n",
       "    2018   903.176949   605.239133  \n",
       "    2019          NaN          NaN  \n",
       "2   2017  1548.482000   820.735000  \n",
       "    2018  1003.392882   857.146338  \n",
       "    2019          NaN          NaN  \n",
       "3   2017  1256.718000  1510.247500  \n",
       "    2018   881.618083  1706.367905  \n",
       "    2019          NaN          NaN  \n",
       "4   2017  3979.102500  2900.490000  \n",
       "    2018  3946.826055  3608.728645  \n",
       "    2019          NaN          NaN  \n",
       "5   2017  4209.540000  2735.686000  \n",
       "    2018  4704.352842  3229.293940  \n",
       "    2019          NaN          NaN  \n",
       "6   2017   602.042500   940.694000  \n",
       "    2018   726.923393   862.469685  \n",
       "    2019          NaN          NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def daily_average_matrix_ann(df):\n",
    "    \n",
    "    matrix = df.groupby([df.index.dayofweek, df.index.month, df.index.year]).agg({'sales': 'mean'})\n",
    "    matrix = matrix.rename_axis(['day', 'month', 'year'])\n",
    "    return matrix.unstack(level=1)\n",
    "\n",
    "daily_average_matrix_ann(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude + Longitude from Yelp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates found for Jupiter Disco\n"
     ]
    }
   ],
   "source": [
    "host = 'https://api.yelp.com'\n",
    "path = '/v3/businesses/search'\n",
    "\n",
    "search_limit = 10\n",
    "\n",
    "# Yelp Authorization Header with API Key\n",
    "headers = {\n",
    "        'Authorization': 'Bearer {}'.format(yelp_api_key) \n",
    "    }\n",
    "\n",
    "# Build Requests Syntax with Yelp Host and Path and URL Paramaters\n",
    "# Return JSON response\n",
    "def request(host, path, url_params=None):\n",
    "    \n",
    "    url_params = url_params or {}\n",
    "    url = '{}{}'.format(host, path)\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=url_params)\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Build URL Params for the Request and provide the host and path\n",
    "def search(term, location):\n",
    "    \n",
    "    url_params = {\n",
    "        'term': term.replace(' ', '+'),\n",
    "        'location': location.replace(' ', '+'),\n",
    "        'limit': search_limit\n",
    "    }\n",
    "    \n",
    "    return request(host, path, url_params=url_params)\n",
    "\n",
    "# Return Coordinates if Exact Match Found\n",
    "def yelp_lat_long(business, location):\n",
    "    \n",
    "    # Call search function here with business name and location\n",
    "    response = search(business, location)\n",
    "    \n",
    "    # Set state to 'No Match' in case no Yelp match found\n",
    "    state = 'No Match'\n",
    "    possible_matches = []\n",
    "    \n",
    "    # Check search returns for match wtith business\n",
    "    for i in range(len(response['businesses'])):\n",
    "\n",
    "        # If match found:\n",
    "        if response['businesses'][i]['name'] == business:\n",
    "\n",
    "            # Local variables to help navigate JSON return\n",
    "            response_ = response['businesses'][0]\n",
    "            name_ = response_['name']\n",
    "\n",
    "            print(f'Coordinates found for {name_}')\n",
    "            state = 'Match Found'\n",
    "            #print(response['businesses'][0])\n",
    "            return response_['coordinates']['latitude'], response_['coordinates']['longitude']\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # If no exact match, append all search returns to list\n",
    "            possible_matches.append(response['businesses'][i]['name'])\n",
    "    \n",
    "    # If no match, show user potential matches\n",
    "    if state == 'No Match':\n",
    "        \n",
    "        print('Exact match not found, did you mean one of the following? \\n')\n",
    "        \n",
    "        for possible_match in possible_matches:\n",
    "            print(possible_match)\n",
    "            \n",
    "        return None, None\n",
    "\n",
    "lat, long = yelp_lat_long(search_business, location)\n",
    "#print(f'Latitude: {lat}\\nLongitude: {long}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darksky API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of Dates of target Weather Data\n",
    "def find_dates(start_date, end_date):\n",
    "    \n",
    "    list_of_days = []\n",
    "    daterange = pd.date_range(start_date, end_date)\n",
    "    for single_date in daterange:\n",
    "        list_of_days.append(single_date.strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    return list_of_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URL to make API Call\n",
    "def build_url(api_key, lat, long, day):\n",
    "    \n",
    "    _base_url = 'https://api.darksky.net/forecast/'\n",
    "    _time = 'T20:00:00'\n",
    "    _url = f'{_base_url}{api_key}/{lat},{long},{day + _time}?America/New_York&exclude=flags'\n",
    "    return _url\n",
    "\n",
    "def make_api_call(url):\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Data from API Call into Dictionaries\n",
    "def parse_data(data):\n",
    "\n",
    "    time = datetime.datetime.fromtimestamp(data['currently']['time']).strftime('%Y-%m-%d')\n",
    "    \n",
    "    try:\n",
    "        entry = {'date': time,\n",
    "                 'temperature': data['currently']['temperature'],\n",
    "                 'apparent_temperature': data['currently']['apparentTemperature'],\n",
    "                 'precip_prob': data['currently']['precipProbability'],\n",
    "                 'summary': data['currently']['icon'],\n",
    "                 'moonphase': data['daily']['data'][0]['moonPhase']}\n",
    "    \n",
    "    except KeyError:\n",
    "        \n",
    "        entry = {'date': time,\n",
    "                 'temperature': 'NaN',\n",
    "                 'apparent_temperature': 'NaN',\n",
    "                 'precip_prob': 'NaN',\n",
    "                 'summary': 'NaN',\n",
    "                 'moonphase': 'NaN'}\n",
    "    \n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of Weather Data Dictionaries & Input Target Dates\n",
    "def weather_call(start_date, end_date, _lat, _long):\n",
    "    \n",
    "    weather = []\n",
    "    list_of_days = find_dates(start_date, end_date)\n",
    "    \n",
    "    for day in list_of_days:\n",
    "        \n",
    "        data = make_api_call(build_url(darksky_api_key, _lat, _long, day))\n",
    "        \n",
    "        weather.append(parse_data(data))\n",
    "    \n",
    "    return weather\n",
    "\n",
    "result = weather_call(start_date, end_date, lat, long);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DataFrame from List of Dictionaries\n",
    "def build_weather_df(api_call_results):\n",
    "\n",
    "    df = pd.DataFrame(api_call_results)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['day_of_week'] = df['date'].dt.weekday\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    #Cast required columns as floats\n",
    "    df[['temperature', 'apparent_temperature', 'precip_prob', 'moonphase']] = df[['temperature', 'apparent_temperature', 'precip_prob', 'moonphase']].astype(float)\n",
    "    \n",
    "    # Fill Temperature NaN with previous day\n",
    "    df['temperature'].fillna(method='ffill',inplace=True)\n",
    "    \n",
    "    #Fill Apparent Temperature with previous day\n",
    "    df['apparent_temperature'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    #Fill moonphase with previous day\n",
    "    df['moonphase'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    #Fill Precipitation Probability with previous day\n",
    "    df['precip_prob'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "weather_df = build_weather_df(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_sales_weather(sales_df, weather_df):\n",
    "    \n",
    "    df = pd.merge(sales_df, weather_df, how='left', on='date')\n",
    "    return df\n",
    "\n",
    "df = join_sales_weather(df, weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN DATAFRAME HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Holiday & $0 in Sales\n",
    "# Pass Other Closed Dates here\n",
    "additional_closed_dates = ['2018-12-24', '2017-12-24', '2017-10-22']\n",
    "closed_dates = [pd.to_datetime(date) for date in additional_closed_dates]\n",
    "\n",
    "def add_features(df):\n",
    "    \n",
    "    try:\n",
    "        # CLOSED FEATURE\n",
    "        cal = calendar()\n",
    "        # Local list of days with zero sales\n",
    "        potential_closed_dates = df[df['sales'] == 0].index\n",
    "        # Enocodes closed days with 1\n",
    "        df['closed'] = np.where((((df.index.isin(potential_closed_dates)) & \\\n",
    "                                  (df.index.isin(cal.holidays(start_date, end_date)))) | df.index.isin(closed_dates)), 1, 0)\n",
    "    except:\n",
    "        # If no Sales Data available (Predict)\n",
    "        df['closed'] = 0\n",
    "    \n",
    "    # POOR WEATHER FEATURE\n",
    "    poor_weather_list = ['rain', 'snow', 'sleet']\n",
    "    df['summary'] = df['summary'].apply(lambda x: x.split('-'))\n",
    "    df['poor_weather'] = np.where(df['summary'].apply(lambda x: np.any(np.in1d(x, poor_weather_list))), 1, 0)\n",
    "    df = df.drop(['summary'], axis=1)\n",
    "    \n",
    "    # THREE DAY WEEKEND FEATURE\n",
    "    sunday_three_days = [date + pd.DateOffset(-1) for date in cal.holidays(start_date, end_date) if date.dayofweek == 0]\n",
    "    df['sunday_three_day'] = np.where(df.index.isin(sunday_three_days), 1, 0)\n",
    "    \n",
    "    monday_three_days = [date for date in cal.holidays(start_date, end_date) if date.dayofweek == 0]\n",
    "    df['monday_three_day'] = np.where(df.index.isin(monday_three_days), 1, 0)\n",
    "    \n",
    "    # MONTH\n",
    "    df['month'] = df.index.month\n",
    "    \n",
    "    return df\n",
    "\n",
    "dfx = add_features(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummies(df):\n",
    "    \n",
    "    daily_dummies = pd.get_dummies(df['day_of_week'], prefix='day')\n",
    "    monthly_dummies = pd.get_dummies(df['month'], prefix='mo')\n",
    "    \n",
    "    df = pd.concat([df, daily_dummies, monthly_dummies], axis=1)\n",
    "    df = df.drop(['day_of_week', 'month'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "dfx = add_dummies(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_interactions = True\n",
    "\n",
    "def add_interactions(df):\n",
    "    \n",
    "    if apply_interactions:\n",
    "        \n",
    "        for i in [col for col in df.columns if col.startswith('day_')]:\n",
    "            \n",
    "            col_name = i + '_X_' + 'poor_weather'\n",
    "            \n",
    "            df[col_name] = df[i] * df['poor_weather']\n",
    "            \n",
    "            for m in [col for col in df.columns if col.startswith('mo_')]:\n",
    "                \n",
    "                col_name = i + '_X_' + m\n",
    "                \n",
    "                df[col_name] = df[i] * df[m]\n",
    "            \n",
    "        return df\n",
    "\n",
    "dfx = add_interactions(dfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test / Train / Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  729\n",
      "Test set:  151\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(df):\n",
    "    \n",
    "    # Separate Target & Features\n",
    "    y = df['sales']\n",
    "    features = df.drop(['sales'], axis=1)\n",
    "    \n",
    "    # Test / Train / Split\n",
    "    train_date_start = '2017-01-01'\n",
    "    train_date_end = '2018-12-31'\n",
    "    \n",
    "    X_train = features[train_date_start:train_date_end]\n",
    "    X_test = features[pd.to_datetime(train_date_end)+pd.DateOffset(1):]\n",
    "    \n",
    "    y_train = y[train_date_start:train_date_end]\n",
    "    y_test = y[pd.to_datetime(train_date_end)+pd.DateOffset(1):]\n",
    "    \n",
    "    # Scale Data\n",
    "    #scaler = StandardScaler()\n",
    "    #X_scaler = scaler.fit(X_train)\n",
    "    #X_train = pd.DataFrame(data = X_scaler.transform(X_train), columns=features.columns)\n",
    "    #X_test = pd.DataFrame(data = X_scaler.transform(X_test), columns=features.columns)\n",
    "    \n",
    "    print('Train set: ', len(X_train))\n",
    "    print('Test set: ', len(X_test))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = prepare_data(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['apparent_temperature', 'moonphase', 'precip_prob', 'temperature',\n",
       "       'closed', 'poor_weather', 'sunday_three_day', 'monday_three_day',\n",
       "       'day_0', 'day_1',\n",
       "       ...\n",
       "       'day_6_X_mo_3', 'day_6_X_mo_4', 'day_6_X_mo_5', 'day_6_X_mo_6',\n",
       "       'day_6_X_mo_7', 'day_6_X_mo_8', 'day_6_X_mo_9', 'day_6_X_mo_10',\n",
       "       'day_6_X_mo_11', 'day_6_X_mo_12'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['temperature', 'moonphase', 'poor_weather', 'precip_prob', 'day_0', 'day_0_X_poor_weather', \\\n",
    "                'mo_1', 'mo_2', 'mo_3', 'mo_4', 'mo_5', 'mo_6', 'mo_7', 'mo_8', 'mo_9', 'mo_10', 'mo_11', 'mo_12']\n",
    "\n",
    "def feature_selection(df):\n",
    "    \n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_train = feature_selection(X_train)\n",
    "X_test = feature_selection(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_model(X_train, y_train):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr_clf = lr.fit(X_train, y_train)\n",
    "    \n",
    "    return lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = linear_regression_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared:   0.8436690996275116 \n",
      "\n",
      "Intercept:   17708763312560.555 \n",
      "\n",
      "Coefficients:  \n",
      "\n",
      "apparent_temperature  -->  4.879601897614076\n",
      "closed  -->  -1021.2742732514957\n",
      "sunday_three_day  -->  1576.0228300451497\n",
      "monday_three_day  -->  -74.7353438553896\n",
      "day_1  -->  -29969550086285.234\n",
      "day_2  -->  -3985240646274.81\n",
      "day_3  -->  -22746200452145.2\n",
      "day_4  -->  -24317866504509.387\n",
      "day_5  -->  -9823504718241.625\n",
      "day_6  -->  -14328158390113.74\n",
      "day_0_X_mo_1  -->  -17708763312091.63\n",
      "day_0_X_mo_2  -->  -17708763312200.01\n",
      "day_0_X_mo_3  -->  -17708763311545.273\n",
      "day_0_X_mo_4  -->  -17708763312402.72\n",
      "day_0_X_mo_5  -->  -17708763312356.617\n",
      "day_0_X_mo_6  -->  -17708763311868.59\n",
      "day_0_X_mo_7  -->  -17708763312130.15\n",
      "day_0_X_mo_8  -->  -17708763312337.246\n",
      "day_0_X_mo_9  -->  -17708763312459.4\n",
      "day_0_X_mo_10  -->  -17708763312158.008\n",
      "day_0_X_mo_11  -->  -17708763311834.164\n",
      "day_0_X_mo_12  -->  -17708763311617.7\n",
      "day_1_X_poor_weather  -->  -13.4794921875\n",
      "day_1_X_mo_1  -->  12260786774421.73\n",
      "day_1_X_mo_2  -->  12260786774464.295\n",
      "day_1_X_mo_3  -->  12260786774248.707\n",
      "day_1_X_mo_4  -->  12260786774254.248\n",
      "day_1_X_mo_5  -->  12260786774151.357\n",
      "day_1_X_mo_6  -->  12260786774561.234\n",
      "day_1_X_mo_7  -->  12260786774255.139\n",
      "day_1_X_mo_8  -->  12260786774127.004\n",
      "day_1_X_mo_9  -->  12260786773964.348\n",
      "day_1_X_mo_10  -->  12260786774338.477\n",
      "day_1_X_mo_11  -->  12260786774276.268\n",
      "day_1_X_mo_12  -->  12260786774275.062\n",
      "day_2_X_poor_weather  -->  -112.818359375\n",
      "day_2_X_mo_1  -->  -13723522665691.697\n",
      "day_2_X_mo_2  -->  -13723522665253.885\n",
      "day_2_X_mo_3  -->  -13723522665509.602\n",
      "day_2_X_mo_4  -->  -13723522665588.232\n",
      "day_2_X_mo_5  -->  -13723522665733.426\n",
      "day_2_X_mo_6  -->  -13723522665614.584\n",
      "day_2_X_mo_7  -->  -13723522665778.81\n",
      "day_2_X_mo_8  -->  -13723522665875.643\n",
      "day_2_X_mo_9  -->  -13723522665688.691\n",
      "day_2_X_mo_10  -->  -13723522665284.223\n",
      "day_2_X_mo_11  -->  -13723522665198.79\n",
      "day_2_X_mo_12  -->  -13723522665565.693\n",
      "day_3_X_poor_weather  -->  -345.10498046875\n",
      "day_3_X_mo_1  -->  5037437140669.855\n",
      "day_3_X_mo_2  -->  5037437140614.575\n",
      "day_3_X_mo_3  -->  5037437140508.33\n",
      "day_3_X_mo_4  -->  5037437140571.749\n",
      "day_3_X_mo_5  -->  5037437140706.752\n",
      "day_3_X_mo_6  -->  5037437140337.949\n",
      "day_3_X_mo_7  -->  5037437140273.705\n",
      "day_3_X_mo_8  -->  5037437140477.005\n",
      "day_3_X_mo_9  -->  5037437140592.637\n",
      "day_3_X_mo_10  -->  5037437140248.328\n",
      "day_3_X_mo_11  -->  5037437140679.197\n",
      "day_3_X_mo_12  -->  5037437141112.902\n",
      "day_4_X_poor_weather  -->  64.32421875\n",
      "day_4_X_mo_1  -->  6609103194709.971\n",
      "day_4_X_mo_2  -->  6609103195575.774\n",
      "day_4_X_mo_3  -->  6609103195311.959\n",
      "day_4_X_mo_4  -->  6609103195326.255\n",
      "day_4_X_mo_5  -->  6609103195120.216\n",
      "day_4_X_mo_6  -->  6609103195057.142\n",
      "day_4_X_mo_7  -->  6609103194197.752\n",
      "day_4_X_mo_8  -->  6609103195154.533\n",
      "day_4_X_mo_9  -->  6609103195503.412\n",
      "day_4_X_mo_10  -->  6609103195209.208\n",
      "day_4_X_mo_11  -->  6609103195694.801\n",
      "day_4_X_mo_12  -->  6609103194966.911\n",
      "day_5_X_poor_weather  -->  -640.1484375\n",
      "day_5_X_mo_1  -->  -7885258590846.674\n",
      "day_5_X_mo_2  -->  -7885258590062.762\n",
      "day_5_X_mo_3  -->  -7885258590198.678\n",
      "day_5_X_mo_4  -->  -7885258590784.532\n",
      "day_5_X_mo_5  -->  -7885258591079.326\n",
      "day_5_X_mo_6  -->  -7885258590791.969\n",
      "day_5_X_mo_7  -->  -7885258591245.902\n",
      "day_5_X_mo_8  -->  -7885258591173.533\n",
      "day_5_X_mo_9  -->  -7885258591130.634\n",
      "day_5_X_mo_10  -->  -7885258590852.941\n",
      "day_5_X_mo_11  -->  -7885258589924.755\n",
      "day_5_X_mo_12  -->  -7885258591376.701\n",
      "day_6_X_poor_weather  -->  104.23681640625\n",
      "day_6_X_mo_1  -->  -3380604922109.4146\n",
      "day_6_X_mo_2  -->  -3380604921746.4385\n",
      "day_6_X_mo_3  -->  -3380604921959.698\n",
      "day_6_X_mo_4  -->  -3380604921937.4507\n",
      "day_6_X_mo_5  -->  -3380604921548.5547\n",
      "day_6_X_mo_6  -->  -3380604922162.808\n",
      "day_6_X_mo_7  -->  -3380604922076.617\n",
      "day_6_X_mo_8  -->  -3380604922212.047\n",
      "day_6_X_mo_9  -->  -3380604921980.222\n",
      "day_6_X_mo_10  -->  -3380604922507.7915\n",
      "day_6_X_mo_11  -->  -3380604922208.7114\n",
      "day_6_X_mo_12  -->  -3380604921955.241\n"
     ]
    }
   ],
   "source": [
    "def lr_score(clf, X_test, y_test):\n",
    "    \n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    print('R-Squared:  ', score, '\\n')\n",
    "    print('Intercept:  ', clf.intercept_, '\\n')\n",
    "    print('Coefficients:  \\n')\n",
    "    \n",
    "    for index, col_name in enumerate(X_test.columns):\n",
    "        print(col_name, ' --> ', clf.coef_[index])\n",
    "        \n",
    "lr_score(lr_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8430598985191586"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1137.3937978320803"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apparent_temperature  -->  4.817462691449859\n",
      "closed  -->  -1018.6840342538887\n",
      "sunday_three_day  -->  1566.788698505379\n",
      "monday_three_day  -->  -76.46194538091541\n",
      "day_1  -->  -606.174467791221\n",
      "day_2  -->  -507.2404257023619\n",
      "day_3  -->  -199.79408513745355\n",
      "day_4  -->  2025.292803086378\n",
      "day_5  -->  2339.1329633955447\n",
      "day_6  -->  -672.3578217030828\n",
      "day_0_X_mo_1  -->  -691.8377044325637\n",
      "day_0_X_mo_2  -->  -773.4832265490014\n",
      "day_0_X_mo_3  -->  -110.1084392617222\n",
      "day_0_X_mo_4  -->  -997.6313236323025\n",
      "day_0_X_mo_5  -->  -907.2664349055415\n",
      "day_0_X_mo_6  -->  -431.2227858661394\n",
      "day_0_X_mo_7  -->  -727.9790354962864\n",
      "day_0_X_mo_8  -->  -899.671313614318\n",
      "day_0_X_mo_9  -->  -1030.6712421818154\n",
      "day_0_X_mo_10  -->  -701.3394340172364\n",
      "day_0_X_mo_11  -->  -402.84585414782975\n",
      "day_0_X_mo_12  -->  -188.22841547830964\n",
      "day_1_X_poor_weather  -->  -11.971208536692805\n",
      "day_1_X_mo_1  -->  155.5569242873423\n",
      "day_1_X_mo_2  -->  216.5508218765768\n",
      "day_1_X_mo_3  -->  -0.0\n",
      "day_1_X_mo_4  -->  5.337757606444567\n",
      "day_1_X_mo_5  -->  -103.20832398413059\n",
      "day_1_X_mo_6  -->  315.44341794452623\n",
      "day_1_X_mo_7  -->  -16.012923424621476\n",
      "day_1_X_mo_8  -->  -116.99139129483339\n",
      "day_1_X_mo_9  -->  -282.8635623887523\n",
      "day_1_X_mo_10  -->  82.97019396122467\n",
      "day_1_X_mo_11  -->  26.893390758125676\n",
      "day_1_X_mo_12  -->  26.21003848152506\n",
      "day_2_X_poor_weather  -->  -99.77302235289305\n",
      "day_2_X_mo_1  -->  -16.3281130157026\n",
      "day_2_X_mo_2  -->  404.1053997669065\n",
      "day_2_X_mo_3  -->  131.13199905641486\n",
      "day_2_X_mo_4  -->  42.79717996545883\n",
      "day_2_X_mo_5  -->  -77.5436242134488\n",
      "day_2_X_mo_6  -->  17.649622362688085\n",
      "day_2_X_mo_7  -->  -116.87342146371995\n",
      "day_2_X_mo_8  -->  -203.23191208196891\n",
      "day_2_X_mo_9  -->  -0.0\n",
      "day_2_X_mo_10  -->  385.71963040652844\n",
      "day_2_X_mo_11  -->  473.81390502719955\n",
      "day_2_X_mo_12  -->  63.92020408023116\n",
      "day_3_X_poor_weather  -->  -355.5705092493221\n",
      "day_3_X_mo_1  -->  160.0148798891016\n",
      "day_3_X_mo_2  -->  104.70518409630515\n",
      "day_3_X_mo_3  -->  -10.433099102157978\n",
      "day_3_X_mo_4  -->  62.97754277308141\n",
      "day_3_X_mo_5  -->  212.89033093808885\n",
      "day_3_X_mo_6  -->  -172.78134288528764\n",
      "day_3_X_mo_7  -->  -231.4921030573314\n",
      "day_3_X_mo_8  -->  -45.45589833753537\n",
      "day_3_X_mo_9  -->  48.35675275190677\n",
      "day_3_X_mo_10  -->  -294.8212894086128\n",
      "day_3_X_mo_11  -->  166.8388008930664\n",
      "day_3_X_mo_12  -->  566.0974210450843\n",
      "day_4_X_poor_weather  -->  69.86014503362078\n",
      "day_4_X_mo_1  -->  -377.71820657316067\n",
      "day_4_X_mo_2  -->  452.26522087272133\n",
      "day_4_X_mo_3  -->  205.2816779338736\n",
      "day_4_X_mo_4  -->  204.08421702549714\n",
      "day_4_X_mo_5  -->  -0.0\n",
      "day_4_X_mo_6  -->  -38.68579831944097\n",
      "day_4_X_mo_7  -->  -887.06708885568\n",
      "day_4_X_mo_8  -->  31.861812994121543\n",
      "day_4_X_mo_9  -->  398.4943686319288\n",
      "day_4_X_mo_10  -->  87.29292768384383\n",
      "day_4_X_mo_11  -->  576.7201166931409\n",
      "day_4_X_mo_12  -->  -132.3939220374875\n",
      "day_5_X_poor_weather  -->  -639.3430134454036\n",
      "day_5_X_mo_1  -->  11.904311015689647\n",
      "day_5_X_mo_2  -->  788.5325724469716\n",
      "day_5_X_mo_3  -->  630.0429556567337\n",
      "day_5_X_mo_4  -->  41.46591191901605\n",
      "day_5_X_mo_5  -->  -222.2495968797291\n",
      "day_5_X_mo_6  -->  57.015769792347996\n",
      "day_5_X_mo_7  -->  -421.2247730785183\n",
      "day_5_X_mo_8  -->  -312.8254633126212\n",
      "day_5_X_mo_9  -->  -281.3598662432712\n",
      "day_5_X_mo_10  -->  7.668792621590082\n",
      "day_5_X_mo_11  -->  929.428994842134\n",
      "day_5_X_mo_12  -->  -541.2428543730808\n",
      "day_6_X_poor_weather  -->  95.91508262782537\n",
      "day_6_X_mo_1  -->  -122.89491782043235\n",
      "day_6_X_mo_2  -->  239.14553913713888\n",
      "day_6_X_mo_3  -->  39.66735322329529\n",
      "day_6_X_mo_4  -->  29.518202858570742\n",
      "day_6_X_mo_5  -->  437.9819364888358\n",
      "day_6_X_mo_6  -->  -159.18403095222783\n",
      "day_6_X_mo_7  -->  -111.02866725198928\n",
      "day_6_X_mo_8  -->  -208.22666280833502\n",
      "day_6_X_mo_9  -->  0.0\n",
      "day_6_X_mo_10  -->  -525.4426469096362\n",
      "day_6_X_mo_11  -->  -214.06467124940107\n",
      "day_6_X_mo_12  -->  42.93091003324952\n"
     ]
    }
   ],
   "source": [
    "lassoReg = Lasso(alpha=0.01)\n",
    "\n",
    "lassoReg.fit(X_train,y_train)\n",
    "\n",
    "pred = lassoReg.predict(X_test)\n",
    "lassoReg.score(X_test, y_test)\n",
    "\n",
    "lassoReg.intercept_\n",
    "\n",
    "for index, col_name in enumerate(X_test.columns):\n",
    "        print(col_name, ' --> ', lassoReg.coef_[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates found for Jupiter Disco\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3469.99475442, 3884.86026832,  638.55936849, 1052.75432309,\n",
       "       1194.14388638,  988.22148534, 1128.13830539])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_df(clf, X_train, date_1, date_2):\n",
    "    \n",
    "    lat, long = yelp_lat_long(search_business, location)\n",
    "    \n",
    "    weather_df = build_weather_df(weather_call(date_1, date_2, lat, long))\n",
    "    df = add_interactions(add_dummies(add_features(weather_df)))\n",
    "    \n",
    "    missing_cols = set(X_train.columns) - set(df.columns)\n",
    "    \n",
    "    for c in missing_cols:\n",
    "        df[c] = 0\n",
    "        \n",
    "    df = df[X_train.columns]\n",
    "\n",
    "    return clf.predict(df)\n",
    "\n",
    "predict_df(lassoReg, X_train, pd.datetime.now().date(), pd.datetime.now().date() + pd.DateOffset(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
