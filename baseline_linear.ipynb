{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import yelp_api_key\n",
    "from config import darksky_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sales Data\n",
    "file = 'bar_x_sales_export.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Dates\n",
    "start_date = '2017-01-01' # Start Date Inclusive\n",
    "end_date = '2019-06-01' # End Date Exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_business = 'Jupiter Disco'\n",
    "location = 'Brooklyn, NY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import / Clean / Prep File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bar_x_sales_export.csv\" has been imported + parsed. The file has 891 rows.\n"
     ]
    }
   ],
   "source": [
    "def import_parse(file):\n",
    "\n",
    "    data = pd.read_csv(file, index_col = 'date', parse_dates=True)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Rename Column to 'sales'\n",
    "    df = df.rename(columns={df.columns[0]: 'sales'})\n",
    "    \n",
    "    # Drop NaN\n",
    "    #df = df.query('sales > 0').copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    print(f'\"{file}\" has been imported + parsed. The file has {len(df)} rows.')\n",
    "    return df\n",
    "\n",
    "df = import_parse(file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, start_date, end_date):\n",
    "    \n",
    "    return df[(df.index > start_date) & (df.index < end_date)]\n",
    "    \n",
    "df = filter_df(df, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>2017</th>\n",
       "      <td>516.3860</td>\n",
       "      <td>647.48250</td>\n",
       "      <td>1183.9425</td>\n",
       "      <td>491.2050</td>\n",
       "      <td>543.816000</td>\n",
       "      <td>555.365000</td>\n",
       "      <td>1212.406000</td>\n",
       "      <td>533.020000</td>\n",
       "      <td>418.412500</td>\n",
       "      <td>529.060000</td>\n",
       "      <td>735.852500</td>\n",
       "      <td>496.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>398.2020</td>\n",
       "      <td>407.79750</td>\n",
       "      <td>1252.3050</td>\n",
       "      <td>313.9940</td>\n",
       "      <td>475.595000</td>\n",
       "      <td>1573.685511</td>\n",
       "      <td>376.968794</td>\n",
       "      <td>690.178243</td>\n",
       "      <td>455.241160</td>\n",
       "      <td>902.620590</td>\n",
       "      <td>1154.696929</td>\n",
       "      <td>1207.864237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>449.1125</td>\n",
       "      <td>381.10750</td>\n",
       "      <td>625.6675</td>\n",
       "      <td>390.3160</td>\n",
       "      <td>440.072500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>2017</th>\n",
       "      <td>878.5540</td>\n",
       "      <td>688.02000</td>\n",
       "      <td>819.7400</td>\n",
       "      <td>780.1650</td>\n",
       "      <td>727.966000</td>\n",
       "      <td>729.102500</td>\n",
       "      <td>691.960000</td>\n",
       "      <td>779.938000</td>\n",
       "      <td>496.820000</td>\n",
       "      <td>1074.068000</td>\n",
       "      <td>631.415000</td>\n",
       "      <td>585.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>808.3400</td>\n",
       "      <td>1208.02000</td>\n",
       "      <td>610.0475</td>\n",
       "      <td>775.2675</td>\n",
       "      <td>759.864000</td>\n",
       "      <td>1676.605227</td>\n",
       "      <td>1065.680822</td>\n",
       "      <td>800.896800</td>\n",
       "      <td>715.204696</td>\n",
       "      <td>737.921757</td>\n",
       "      <td>903.176949</td>\n",
       "      <td>605.239133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>613.3100</td>\n",
       "      <td>580.39750</td>\n",
       "      <td>686.0950</td>\n",
       "      <td>934.6300</td>\n",
       "      <td>815.617500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>2017</th>\n",
       "      <td>829.3400</td>\n",
       "      <td>1149.60250</td>\n",
       "      <td>1090.1660</td>\n",
       "      <td>858.7200</td>\n",
       "      <td>955.394000</td>\n",
       "      <td>830.735000</td>\n",
       "      <td>637.622500</td>\n",
       "      <td>665.670000</td>\n",
       "      <td>645.045000</td>\n",
       "      <td>876.327500</td>\n",
       "      <td>1548.482000</td>\n",
       "      <td>820.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>725.4540</td>\n",
       "      <td>1342.47750</td>\n",
       "      <td>717.5500</td>\n",
       "      <td>995.0500</td>\n",
       "      <td>776.454000</td>\n",
       "      <td>1161.861426</td>\n",
       "      <td>1137.068591</td>\n",
       "      <td>971.995906</td>\n",
       "      <td>1286.541929</td>\n",
       "      <td>1667.758492</td>\n",
       "      <td>1003.392882</td>\n",
       "      <td>857.146338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>735.0040</td>\n",
       "      <td>649.08750</td>\n",
       "      <td>1626.9850</td>\n",
       "      <td>1120.8225</td>\n",
       "      <td>716.862000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>2017</th>\n",
       "      <td>1355.0125</td>\n",
       "      <td>1357.96000</td>\n",
       "      <td>908.7360</td>\n",
       "      <td>1166.2575</td>\n",
       "      <td>1293.222500</td>\n",
       "      <td>1025.390000</td>\n",
       "      <td>1074.647500</td>\n",
       "      <td>1182.468000</td>\n",
       "      <td>1332.415000</td>\n",
       "      <td>762.650000</td>\n",
       "      <td>1256.718000</td>\n",
       "      <td>1510.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1183.1725</td>\n",
       "      <td>1066.41475</td>\n",
       "      <td>1345.5960</td>\n",
       "      <td>1346.2375</td>\n",
       "      <td>1545.610505</td>\n",
       "      <td>1236.101679</td>\n",
       "      <td>1115.645611</td>\n",
       "      <td>1361.021963</td>\n",
       "      <td>1242.712945</td>\n",
       "      <td>1014.373708</td>\n",
       "      <td>881.618083</td>\n",
       "      <td>1706.367905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1157.4340</td>\n",
       "      <td>1268.69000</td>\n",
       "      <td>1112.1200</td>\n",
       "      <td>1728.0250</td>\n",
       "      <td>1403.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>2017</th>\n",
       "      <td>2827.9725</td>\n",
       "      <td>3204.24750</td>\n",
       "      <td>3060.9860</td>\n",
       "      <td>2949.0750</td>\n",
       "      <td>3289.650000</td>\n",
       "      <td>2912.632000</td>\n",
       "      <td>2128.480000</td>\n",
       "      <td>3182.207500</td>\n",
       "      <td>3674.406000</td>\n",
       "      <td>3193.820000</td>\n",
       "      <td>3979.102500</td>\n",
       "      <td>2900.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3065.4600</td>\n",
       "      <td>4349.03750</td>\n",
       "      <td>4042.1680</td>\n",
       "      <td>4316.6850</td>\n",
       "      <td>3706.467500</td>\n",
       "      <td>4080.084032</td>\n",
       "      <td>3189.473347</td>\n",
       "      <td>3908.243814</td>\n",
       "      <td>4170.388811</td>\n",
       "      <td>3877.366825</td>\n",
       "      <td>3946.826055</td>\n",
       "      <td>3608.728645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>3487.0125</td>\n",
       "      <td>4170.30000</td>\n",
       "      <td>3691.6700</td>\n",
       "      <td>4244.4200</td>\n",
       "      <td>3902.230000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>2017</th>\n",
       "      <td>2920.9700</td>\n",
       "      <td>3991.26250</td>\n",
       "      <td>3673.6275</td>\n",
       "      <td>3290.3240</td>\n",
       "      <td>3079.322500</td>\n",
       "      <td>3354.785000</td>\n",
       "      <td>2944.338000</td>\n",
       "      <td>2830.012500</td>\n",
       "      <td>3136.190000</td>\n",
       "      <td>3370.617500</td>\n",
       "      <td>4209.540000</td>\n",
       "      <td>2735.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>4337.5900</td>\n",
       "      <td>4444.53750</td>\n",
       "      <td>4625.7580</td>\n",
       "      <td>4243.9700</td>\n",
       "      <td>3694.255000</td>\n",
       "      <td>4341.739711</td>\n",
       "      <td>3875.997336</td>\n",
       "      <td>4075.045577</td>\n",
       "      <td>3768.836186</td>\n",
       "      <td>4195.143800</td>\n",
       "      <td>4704.352842</td>\n",
       "      <td>3229.293940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>3573.1525</td>\n",
       "      <td>4498.55500</td>\n",
       "      <td>4450.1420</td>\n",
       "      <td>4623.2500</td>\n",
       "      <td>4610.585000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th>2017</th>\n",
       "      <td>1074.6900</td>\n",
       "      <td>1550.90000</td>\n",
       "      <td>643.9475</td>\n",
       "      <td>761.9100</td>\n",
       "      <td>1310.082500</td>\n",
       "      <td>675.692500</td>\n",
       "      <td>605.934000</td>\n",
       "      <td>533.185000</td>\n",
       "      <td>941.972500</td>\n",
       "      <td>529.680000</td>\n",
       "      <td>602.042500</td>\n",
       "      <td>940.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>678.0800</td>\n",
       "      <td>1070.21750</td>\n",
       "      <td>705.7325</td>\n",
       "      <td>744.2500</td>\n",
       "      <td>1853.280000</td>\n",
       "      <td>652.400316</td>\n",
       "      <td>892.488110</td>\n",
       "      <td>726.787170</td>\n",
       "      <td>1332.109718</td>\n",
       "      <td>418.156200</td>\n",
       "      <td>726.923393</td>\n",
       "      <td>862.469685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>743.0425</td>\n",
       "      <td>747.23250</td>\n",
       "      <td>799.1100</td>\n",
       "      <td>662.0525</td>\n",
       "      <td>1955.124000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sales                                                 \\\n",
       "month            1           2          3          4            5    \n",
       "day year                                                             \n",
       "0   2017   516.3860   647.48250  1183.9425   491.2050   543.816000   \n",
       "    2018   398.2020   407.79750  1252.3050   313.9940   475.595000   \n",
       "    2019   449.1125   381.10750   625.6675   390.3160   440.072500   \n",
       "1   2017   878.5540   688.02000   819.7400   780.1650   727.966000   \n",
       "    2018   808.3400  1208.02000   610.0475   775.2675   759.864000   \n",
       "    2019   613.3100   580.39750   686.0950   934.6300   815.617500   \n",
       "2   2017   829.3400  1149.60250  1090.1660   858.7200   955.394000   \n",
       "    2018   725.4540  1342.47750   717.5500   995.0500   776.454000   \n",
       "    2019   735.0040   649.08750  1626.9850  1120.8225   716.862000   \n",
       "3   2017  1355.0125  1357.96000   908.7360  1166.2575  1293.222500   \n",
       "    2018  1183.1725  1066.41475  1345.5960  1346.2375  1545.610505   \n",
       "    2019  1157.4340  1268.69000  1112.1200  1728.0250  1403.620000   \n",
       "4   2017  2827.9725  3204.24750  3060.9860  2949.0750  3289.650000   \n",
       "    2018  3065.4600  4349.03750  4042.1680  4316.6850  3706.467500   \n",
       "    2019  3487.0125  4170.30000  3691.6700  4244.4200  3902.230000   \n",
       "5   2017  2920.9700  3991.26250  3673.6275  3290.3240  3079.322500   \n",
       "    2018  4337.5900  4444.53750  4625.7580  4243.9700  3694.255000   \n",
       "    2019  3573.1525  4498.55500  4450.1420  4623.2500  4610.585000   \n",
       "6   2017  1074.6900  1550.90000   643.9475   761.9100  1310.082500   \n",
       "    2018   678.0800  1070.21750   705.7325   744.2500  1853.280000   \n",
       "    2019   743.0425   747.23250   799.1100   662.0525  1955.124000   \n",
       "\n",
       "                                                                           \\\n",
       "month              6            7            8            9            10   \n",
       "day year                                                                    \n",
       "0   2017   555.365000  1212.406000   533.020000   418.412500   529.060000   \n",
       "    2018  1573.685511   376.968794   690.178243   455.241160   902.620590   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "1   2017   729.102500   691.960000   779.938000   496.820000  1074.068000   \n",
       "    2018  1676.605227  1065.680822   800.896800   715.204696   737.921757   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "2   2017   830.735000   637.622500   665.670000   645.045000   876.327500   \n",
       "    2018  1161.861426  1137.068591   971.995906  1286.541929  1667.758492   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "3   2017  1025.390000  1074.647500  1182.468000  1332.415000   762.650000   \n",
       "    2018  1236.101679  1115.645611  1361.021963  1242.712945  1014.373708   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "4   2017  2912.632000  2128.480000  3182.207500  3674.406000  3193.820000   \n",
       "    2018  4080.084032  3189.473347  3908.243814  4170.388811  3877.366825   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "5   2017  3354.785000  2944.338000  2830.012500  3136.190000  3370.617500   \n",
       "    2018  4341.739711  3875.997336  4075.045577  3768.836186  4195.143800   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "6   2017   675.692500   605.934000   533.185000   941.972500   529.680000   \n",
       "    2018   652.400316   892.488110   726.787170  1332.109718   418.156200   \n",
       "    2019          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "                                    \n",
       "month              11           12  \n",
       "day year                            \n",
       "0   2017   735.852500   496.392500  \n",
       "    2018  1154.696929  1207.864237  \n",
       "    2019          NaN          NaN  \n",
       "1   2017   631.415000   585.697500  \n",
       "    2018   903.176949   605.239133  \n",
       "    2019          NaN          NaN  \n",
       "2   2017  1548.482000   820.735000  \n",
       "    2018  1003.392882   857.146338  \n",
       "    2019          NaN          NaN  \n",
       "3   2017  1256.718000  1510.247500  \n",
       "    2018   881.618083  1706.367905  \n",
       "    2019          NaN          NaN  \n",
       "4   2017  3979.102500  2900.490000  \n",
       "    2018  3946.826055  3608.728645  \n",
       "    2019          NaN          NaN  \n",
       "5   2017  4209.540000  2735.686000  \n",
       "    2018  4704.352842  3229.293940  \n",
       "    2019          NaN          NaN  \n",
       "6   2017   602.042500   940.694000  \n",
       "    2018   726.923393   862.469685  \n",
       "    2019          NaN          NaN  "
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def daily_average_matrix_ann(df):\n",
    "    \n",
    "    matrix = df.groupby([df.index.dayofweek, df.index.month, df.index.year]).agg({'sales': 'mean'})\n",
    "    matrix = matrix.rename_axis(['day', 'month', 'year'])\n",
    "    return matrix.unstack(level=1)\n",
    "\n",
    "daily_average_matrix_ann(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude + Longitude from Yelp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates found for Jupiter Disco\n"
     ]
    }
   ],
   "source": [
    "host = 'https://api.yelp.com'\n",
    "path = '/v3/businesses/search'\n",
    "\n",
    "search_limit = 10\n",
    "\n",
    "# Yelp Authorization Header with API Key\n",
    "headers = {\n",
    "        'Authorization': 'Bearer {}'.format(yelp_api_key) \n",
    "    }\n",
    "\n",
    "# Build Requests Syntax with Yelp Host and Path and URL Paramaters\n",
    "# Return JSON response\n",
    "def request(host, path, url_params=None):\n",
    "    \n",
    "    url_params = url_params or {}\n",
    "    url = '{}{}'.format(host, path)\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=url_params)\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Build URL Params for the Request and provide the host and path\n",
    "def search(term, location):\n",
    "    \n",
    "    url_params = {\n",
    "        'term': term.replace(' ', '+'),\n",
    "        'location': location.replace(' ', '+'),\n",
    "        'limit': search_limit\n",
    "    }\n",
    "    \n",
    "    return request(host, path, url_params=url_params)\n",
    "\n",
    "# Return Coordinates if Exact Match Found\n",
    "def yelp_lat_long(business, location):\n",
    "    \n",
    "    # Call search function here with business name and location\n",
    "    response = search(business, location)\n",
    "    \n",
    "    # Set state to 'No Match' in case no Yelp match found\n",
    "    state = 'No Match'\n",
    "    possible_matches = []\n",
    "    \n",
    "    # Check search returns for match wtith business\n",
    "    for i in range(len(response['businesses'])):\n",
    "\n",
    "        # If match found:\n",
    "        if response['businesses'][i]['name'] == business:\n",
    "\n",
    "            # Local variables to help navigate JSON return\n",
    "            response_ = response['businesses'][0]\n",
    "            name_ = response_['name']\n",
    "\n",
    "            print(f'Coordinates found for {name_}')\n",
    "            state = 'Match Found'\n",
    "            #print(response['businesses'][0])\n",
    "            return response_['coordinates']['latitude'], response_['coordinates']['longitude']\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # If no exact match, append all search returns to list\n",
    "            possible_matches.append(response['businesses'][i]['name'])\n",
    "    \n",
    "    # If no match, show user potential matches\n",
    "    if state == 'No Match':\n",
    "        \n",
    "        print('Exact match not found, did you mean one of the following? \\n')\n",
    "        \n",
    "        for possible_match in possible_matches:\n",
    "            print(possible_match)\n",
    "            \n",
    "        return None, None\n",
    "\n",
    "lat, long = yelp_lat_long(search_business, location)\n",
    "#print(f'Latitude: {lat}\\nLongitude: {long}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darksky API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of Dates of target Weather Data\n",
    "def find_dates(start_date, end_date):\n",
    "    \n",
    "    list_of_days = []\n",
    "    daterange = pd.date_range(start_date, end_date)\n",
    "    for single_date in daterange:\n",
    "        list_of_days.append(single_date.strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    return list_of_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URL to make API Call\n",
    "def build_url(api_key, lat, long, day):\n",
    "    \n",
    "    _base_url = 'https://api.darksky.net/forecast/'\n",
    "    _time = 'T21:00:00'\n",
    "    _url = f'{_base_url}{api_key}/{lat},{long},{day + _time}?America/New_York&exclude=flags'\n",
    "    return _url\n",
    "\n",
    "def make_api_call(url):\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Data from API Call into Dictionaries\n",
    "def parse_data(data):\n",
    "\n",
    "    time = datetime.datetime.fromtimestamp(data['currently']['time']).strftime('%Y-%m-%d')\n",
    "    \n",
    "    try:\n",
    "        entry = {'date': time,\n",
    "                 'temperature': data['currently']['temperature'],\n",
    "                 'apparent_temperature': data['currently']['apparentTemperature'],\n",
    "                 'precip_prob': data['currently']['precipProbability'],\n",
    "                 'summary': data['currently']['icon'],\n",
    "                 'moonphase': data['daily']['data'][0]['moonPhase']}\n",
    "    \n",
    "    except KeyError:\n",
    "        \n",
    "        entry = {'date': time,\n",
    "                 'temperature': 'NaN',\n",
    "                 'apparent_temperature': 'NaN',\n",
    "                 'precip_prob': 'NaN',\n",
    "                 'summary': 'NaN',\n",
    "                 'moonphase': 'NaN'}\n",
    "    \n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of Weather Data Dictionaries & Input Target Dates\n",
    "def weather_call(start_date, end_date, _lat, _long):\n",
    "    \n",
    "    weather = []\n",
    "    list_of_days = find_dates(start_date, end_date)\n",
    "    \n",
    "    for day in list_of_days:\n",
    "        \n",
    "        data = make_api_call(build_url(darksky_api_key, _lat, _long, day))\n",
    "        \n",
    "        weather.append(parse_data(data))\n",
    "    \n",
    "    return weather\n",
    "\n",
    "result = weather_call(start_date, end_date, lat, long);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DataFrame from List of Dictionaries\n",
    "def build_weather_df(api_call_results):\n",
    "\n",
    "    df = pd.DataFrame(api_call_results)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['day_of_week'] = df['date'].dt.weekday\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    #Cast required columns as floats\n",
    "    df[['temperature', 'apparent_temperature', 'precip_prob', 'moonphase']] = df[['temperature', 'apparent_temperature', 'precip_prob', 'moonphase']].astype(float)\n",
    "    \n",
    "    # Fill Temperature NaN with previous day\n",
    "    df['temperature'].fillna(method='ffill',inplace=True)\n",
    "    \n",
    "    #Fill Apparent Temperature with previous day\n",
    "    df['apparent_temperature'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    #Fill moonphase with previous day\n",
    "    df['moonphase'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    #Fill Precipitation Probability with previous day\n",
    "    df['precip_prob'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "weather_df = build_weather_df(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_sales_weather(sales_df, weather_df):\n",
    "    \n",
    "    df = pd.merge(sales_df, weather_df, how='left', on='date')\n",
    "    return df\n",
    "\n",
    "df = join_sales_weather(df, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Holiday & $0 in Sales\n",
    "# Pass Other Closed Dates here\n",
    "additional_closed_dates = ['2018-12-24', '2017-12-24', '2017-10-22']\n",
    "closed_dates = [pd.to_datetime(date) for date in additional_closed_dates]\n",
    "\n",
    "def add_features(df):\n",
    "    \n",
    "    try:\n",
    "        # CLOSED FEATURE\n",
    "        cal = calendar()\n",
    "        # Local list of days with zero sales\n",
    "        potential_closed_dates = df[df['sales'] == 0].index\n",
    "        # Enocodes closed days with 1\n",
    "        df['closed'] = np.where((((df.index.isin(potential_closed_dates)) & \\\n",
    "                                  (df.index.isin(cal.holidays(start_date, end_date)))) | df.index.isin(closed_dates)), 1, 0)\n",
    "    except:\n",
    "        # If no Sales Data available (Predict)\n",
    "        df['closed'] = 0\n",
    "    \n",
    "    # POOR WEATHER FEATURE\n",
    "    poor_weather_list = ['rain', 'snow', 'sleet']\n",
    "    df['summary'] = df['summary'].apply(lambda x: x.split('-'))\n",
    "    df['poor_weather'] = np.where(df['summary'].apply(lambda x: np.any(np.in1d(x, poor_weather_list))), 1, 0)\n",
    "    df = df.drop(['summary'], axis=1)\n",
    "    \n",
    "    # THREE DAY WEEKEND FEATURE\n",
    "    sunday_three_days = [date + pd.DateOffset(-1) for date in cal.holidays(start_date, end_date) if date.dayofweek == 0]\n",
    "    df['sunday_three_day'] = np.where(df.index.isin(sunday_three_days), 1, 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "dfx = add_features(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_daily_dummies(df):\n",
    "    \n",
    "    daily_dummies = pd.get_dummies(df['day_of_week'], prefix='day')\n",
    "    \n",
    "    df = pd.concat([df, daily_dummies], axis=1)\n",
    "    df = df.drop(['day_of_week'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "dfx = add_daily_dummies(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_interactions = True\n",
    "\n",
    "def add_interactions(df):\n",
    "    \n",
    "    if apply_interactions:\n",
    "        \n",
    "        for i in [col for col in df.columns if col.startswith('day_')]:\n",
    "            \n",
    "            col_name = i + '_X_' + 'poor_weather'\n",
    "            \n",
    "            df[col_name] = df[i] * df['poor_weather']\n",
    "        \n",
    "        return df\n",
    "\n",
    "dfx = add_interactions(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales                   0\n",
       "apparent_temperature    0\n",
       "moonphase               0\n",
       "precip_prob             0\n",
       "temperature             0\n",
       "closed                  0\n",
       "poor_weather            0\n",
       "sunday_three_day        0\n",
       "day_0                   0\n",
       "day_1                   0\n",
       "day_2                   0\n",
       "day_3                   0\n",
       "day_4                   0\n",
       "day_5                   0\n",
       "day_6                   0\n",
       "day_0_X_poor_weather    0\n",
       "day_1_X_poor_weather    0\n",
       "day_2_X_poor_weather    0\n",
       "day_3_X_poor_weather    0\n",
       "day_4_X_poor_weather    0\n",
       "day_5_X_poor_weather    0\n",
       "day_6_X_poor_weather    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test / Train / Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  729\n",
      "Test set:  151\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(df):\n",
    "    \n",
    "    # Separate Target & Features\n",
    "    y = df['sales']\n",
    "    features = df.drop(['sales'], axis=1)\n",
    "    \n",
    "    # Test / Train / Split\n",
    "    train_date_start = '2017-01-01'\n",
    "    train_date_end = '2018-12-31'\n",
    "    \n",
    "    X_train = features[train_date_start:train_date_end]\n",
    "    X_test = features[pd.to_datetime(train_date_end)+pd.DateOffset(1):]\n",
    "    \n",
    "    y_train = y[train_date_start:train_date_end]\n",
    "    y_test = y[pd.to_datetime(train_date_end)+pd.DateOffset(1):]\n",
    "    \n",
    "    #Scale Data\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaler = scaler.fit(X_train)\n",
    "#     X_train = pd.DataFrame(data = X_scaler.transform(X_train), columns=features.columns)\n",
    "#     X_test = pd.DataFrame(data = X_scaler.transform(X_test), columns=features.columns)\n",
    "    \n",
    "    print('Train set: ', len(X_train))\n",
    "    print('Test set: ', len(X_test))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = prepare_data(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['temperature', 'moonphase', 'poor_weather', 'precip_prob', 'day_0', 'day_0_X_poor_weather']\n",
    "\n",
    "def feature_selection(df):\n",
    "    \n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_train = feature_selection(X_train)\n",
    "X_test = feature_selection(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_model(X_train, y_train):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr_clf = lr.fit(X_train, y_train)\n",
    "    \n",
    "    return lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = linear_regression_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared:   0.8208877029844879 \n",
      "\n",
      "Intercept:   733.8145180882542 \n",
      "\n",
      "Coefficients:  \n",
      "\n",
      "apparent_temperature --> 0.07306238638493615\n",
      "closed --> -1059.9449139877122\n",
      "sunday_three_day --> 1584.0805047679003\n",
      "day_1 --> 118.48951673354979\n",
      "day_2 --> 244.37849471284707\n",
      "day_3 --> 502.3232704414501\n",
      "day_4 --> 2797.0814361341872\n",
      "day_5 --> 3014.783414199912\n",
      "day_6 --> -57.79829123494159\n",
      "day_1_X_poor_weather --> -247.4158310771797\n",
      "day_2_X_poor_weather --> 64.17860101505023\n",
      "day_3_X_poor_weather --> -44.471754962573705\n",
      "day_4_X_poor_weather --> -605.6507489305575\n",
      "day_5_X_poor_weather --> -421.3489952017143\n",
      "day_6_X_poor_weather --> 101.91988173501477\n"
     ]
    }
   ],
   "source": [
    "def lr_score(clf, X_test, y_test):\n",
    "    \n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    print('R-Squared:  ', score, '\\n')\n",
    "    print('Intercept:  ', clf.intercept_, '\\n')\n",
    "    print('Coefficients:  \\n')\n",
    "    \n",
    "    for index, col_name in enumerate(X_test.columns):\n",
    "        print(col_name, '-->', clf.coef_[index])\n",
    "        \n",
    "lr_score(lr_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates found for Jupiter Disco\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1241.7336367 , 3536.0848449 , 3753.74371616,  680.95232168,\n",
       "        739.03409497,  857.57840849, 1047.15573888])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_df(clf, date_1, date_2):\n",
    "    \n",
    "    lat, long = yelp_lat_long(search_business, location)\n",
    "    \n",
    "    weather_df = build_weather_df(weather_call(date_1, date_2, lat, long))\n",
    "    df = feature_selection(add_interactions(add_daily_dummies(add_features(weather_df))))\n",
    "    \n",
    "    return clf.predict(df)\n",
    "\n",
    "predict_df(lr_clf, pd.datetime.now().date(), pd.datetime.now().date() + pd.DateOffset(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
